{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93c3877",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T07:37:30.207856Z",
     "start_time": "2023-06-09T07:37:30.205787Z"
    }
   },
   "outputs": [],
   "source": [
    "# reference: https://github.com/sicara/easy-few-shot-learning/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d269158",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T07:45:54.742194Z",
     "start_time": "2023-06-09T07:45:49.066963Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import timm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import glob\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from easyfsl.samplers import TaskSampler\n",
    "from easyfsl.utils import plot_images, sliding_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5476fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T07:46:01.847160Z",
     "start_time": "2023-06-09T07:45:54.752191Z"
    }
   },
   "outputs": [],
   "source": [
    "dinov2_backbone = timm.create_model(\n",
    "    'vit_small_patch14_dinov2.lvd142m',\n",
    "    pretrained=True,\n",
    "    img_size=224,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10187400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T07:46:01.851495Z",
     "start_time": "2023-06-09T07:46:01.849095Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = create_transform(\n",
    "    input_size=(3, 224, 224),\n",
    "    mean=(0.485, 0.456, 0.406),\n",
    "    std=(0.229, 0.224, 0.225),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7646401a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T07:46:01.860528Z",
     "start_time": "2023-06-09T07:46:01.852747Z"
    }
   },
   "outputs": [],
   "source": [
    "aug_transform = create_transform(\n",
    "    input_size=(3, 224, 224),\n",
    "    mean=(0.485, 0.456, 0.406),\n",
    "    std=(0.229, 0.224, 0.225),\n",
    "    is_training=True,\n",
    "    auto_augment='rand-m9-mstd0.5',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f9921",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T07:46:01.871014Z",
     "start_time": "2023-06-09T07:46:01.861705Z"
    }
   },
   "outputs": [],
   "source": [
    "class PrototypicalNetworks(nn.Module):\n",
    "    def __init__(self, backbone: nn.Module):\n",
    "        super(PrototypicalNetworks, self).__init__()\n",
    "        self.backbone = backbone\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        support_images: torch.Tensor,\n",
    "        support_labels: torch.Tensor,\n",
    "        query_images: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        z_support = self.backbone.forward(support_images)\n",
    "        z_query = self.backbone.forward(query_images)\n",
    "\n",
    "        n_way = len(torch.unique(support_labels))\n",
    "        z_proto = torch.cat(\n",
    "            [\n",
    "                z_support[torch.nonzero(support_labels == label)].mean(0)\n",
    "                for label in range(n_way)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        dists = torch.cdist(z_query, z_proto)\n",
    "\n",
    "        scores = -dists\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd9a9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T07:46:02.086910Z",
     "start_time": "2023-06-09T07:46:01.872271Z"
    }
   },
   "outputs": [],
   "source": [
    "model = PrototypicalNetworks(dinov2_backbone).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615b9bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T07:46:02.092160Z",
     "start_time": "2023-06-09T07:46:02.089720Z"
    }
   },
   "outputs": [],
   "source": [
    "my_transform = lambda x: torch.stack([transform(x), aug_transform(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2c3a36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T07:46:02.103960Z",
     "start_time": "2023-06-09T07:46:02.093366Z"
    }
   },
   "outputs": [],
   "source": [
    "train_set = ImageFolder(\n",
    "    root=\"./miniimagenet\",\n",
    "    transform=my_transform,\n",
    ")\n",
    "test_set = ImageFolder(\n",
    "    root=\"./miniimagenet\",\n",
    "    transform=my_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d221463",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T07:46:05.275589Z",
     "start_time": "2023-06-09T07:46:02.105716Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_WAY = 4\n",
    "N_SHOT = 5\n",
    "N_QUERY = 10\n",
    "N_EVALUATION_TASKS = 10\n",
    "\n",
    "test_set.get_labels = lambda: [\n",
    "    instance[1] for instance in test_set\n",
    "]\n",
    "test_sampler = TaskSampler(\n",
    "    test_set, n_way=N_WAY, n_shot=N_SHOT, n_query=N_QUERY, n_tasks=N_EVALUATION_TASKS\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_sampler=test_sampler,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=test_sampler.episodic_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4de2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRAINING_EPISODES = 40000\n",
    "N_VALIDATION_TASKS = 100\n",
    "\n",
    "train_set.get_labels = lambda: [instance[1] for instance in train_set]\n",
    "train_sampler = TaskSampler(\n",
    "    train_set, n_way=N_WAY, n_shot=N_SHOT, n_query=N_QUERY, n_tasks=N_TRAINING_EPISODES\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_sampler=train_sampler,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=train_sampler.episodic_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5752d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def fit(\n",
    "    support_images: torch.Tensor,\n",
    "    support_labels: torch.Tensor,\n",
    "    query_images: torch.Tensor,\n",
    "    query_labels: torch.Tensor,\n",
    ") -> float:\n",
    "    optimizer.zero_grad()\n",
    "    classification_scores = model(\n",
    "        support_images.cuda(), support_labels.cuda(), query_images.cuda()\n",
    "    )\n",
    "\n",
    "    loss = criterion(classification_scores, query_labels.cuda())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b145ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_update_frequency = 10\n",
    "\n",
    "all_loss = []\n",
    "model.train()\n",
    "with tqdm(enumerate(train_loader), total=len(train_loader)) as tqdm_train:\n",
    "    for episode_index, (\n",
    "        support_images,\n",
    "        support_labels,\n",
    "        query_images,\n",
    "        query_labels,\n",
    "        _,\n",
    "    ) in tqdm_train:\n",
    "        support_images = support_images[:, 0, :, :, :]\n",
    "        query_images = query_images[:, 0, :, :, :]\n",
    "    \n",
    "        loss_value = fit(support_images, support_labels, query_images, query_labels)\n",
    "        all_loss.append(loss_value)\n",
    "\n",
    "        if episode_index % log_update_frequency == 0:\n",
    "            tqdm_train.set_postfix(loss=sliding_average(all_loss, log_update_frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8739d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8a599d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T07:49:33.389850Z",
     "start_time": "2023-06-09T07:49:33.377844Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_on_one_task(\n",
    "    support_images: torch.Tensor,\n",
    "    support_labels: torch.Tensor,\n",
    "    query_images: torch.Tensor,\n",
    "    query_labels: torch.Tensor,\n",
    ") -> [int, int]:\n",
    "    \n",
    "    origin_support_images = support_images[:, 0, :, :, :]\n",
    "    augment_support_images = support_images[:, 1, :, :, :]\n",
    "    query_images = query_images[:, 0, :, :, :]\n",
    "    \n",
    "    ft_model = deepcopy(model)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(ft_model.parameters(), lr=1e-5)\n",
    "    for _ in range(5):\n",
    "        optimizer.zero_grad()\n",
    "        classification_scores = ft_model(\n",
    "            origin_support_images.cuda(), support_labels.cuda(), augment_support_images.cuda()\n",
    "        )\n",
    "\n",
    "        loss = criterion(classification_scores, support_labels.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    ft_model.eval()\n",
    "    with torch.no_grad():\n",
    "        n_correct = (\n",
    "            torch.max(\n",
    "                ft_model(origin_support_images.cuda(), support_labels.cuda(), query_images.cuda())\n",
    "                .detach()\n",
    "                .data,\n",
    "                1,\n",
    "            )[1]\n",
    "            == query_labels.cuda()\n",
    "        ).sum().item()\n",
    "        \n",
    "    del ft_model\n",
    "    \n",
    "    return n_correct, len(query_labels)\n",
    "\n",
    "\n",
    "def evaluate(data_loader: DataLoader):\n",
    "    total_predictions = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for episode_index, (\n",
    "        support_images,\n",
    "        support_labels,\n",
    "        query_images,\n",
    "        query_labels,\n",
    "        class_ids,\n",
    "    ) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "\n",
    "        correct, total = evaluate_on_one_task(\n",
    "            support_images, support_labels, query_images, query_labels\n",
    "        )\n",
    "\n",
    "        total_predictions += total\n",
    "        correct_predictions += correct\n",
    "\n",
    "    print(\n",
    "        f\"Model tested on {len(data_loader)} tasks. Accuracy: {(100 * correct_predictions/total_predictions):.2f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46b9b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImageFolder(\n",
    "    root=\"./rabbit_breed\",\n",
    "    transform=my_transform,\n",
    ")\n",
    "test_set.get_labels = lambda: [\n",
    "    instance[1] for instance in test_set\n",
    "]\n",
    "test_sampler = TaskSampler(\n",
    "    test_sampler, n_way=4, n_shot=5, n_query=10, n_tasks=100,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_sampler=test_sampler,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=test_sampler.episodic_collate_fn,\n",
    ")\n",
    "\n",
    "evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bfdbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImageFolder(\n",
    "    root=\"./rabbit_breed\",\n",
    "    transform=my_transform,\n",
    ")\n",
    "test_set.get_labels = lambda: [\n",
    "    instance[1] for instance in test_set\n",
    "]\n",
    "test_sampler = TaskSampler(\n",
    "    test_sampler, n_way=4, n_shot=1, n_query=10, n_tasks=100,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_sampler=test_sampler,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=test_sampler.episodic_collate_fn,\n",
    ")\n",
    "\n",
    "evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd02320",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImageFolder(\n",
    "    root=\"./CUB_200_2011\",\n",
    "    transform=my_transform,\n",
    ")\n",
    "test_set.get_labels = lambda: [\n",
    "    instance[1] for instance in test_set\n",
    "]\n",
    "test_sampler = TaskSampler(\n",
    "    test_sampler, n_way=5, n_shot=1, n_query=10, n_tasks=100,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_sampler=test_sampler,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=test_sampler.episodic_collate_fn,\n",
    ")\n",
    "\n",
    "evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ad2014",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = ImageFolder(\n",
    "    root=\"./CUB_200_2011\",\n",
    "    transform=my_transform,\n",
    ")\n",
    "test_set.get_labels = lambda: [\n",
    "    instance[1] for instance in test_set\n",
    "]\n",
    "test_sampler = TaskSampler(\n",
    "    test_sampler, n_way=5, n_shot=5, n_query=10, n_tasks=100,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_sampler=test_sampler,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    collate_fn=test_sampler.episodic_collate_fn,\n",
    ")\n",
    "\n",
    "evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19b97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8accbf95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aec99c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c68714a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
